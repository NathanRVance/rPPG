#!/usr/bin/env python3
# PYTHON_ARGCOMPLETE_OK

import numpy as np
from pathlib import Path
from rPPG.utils import modelLoader
from rPPG.utils import evaluate
from rPPG.utils import tables
import json
from rPPG.utils import npio
from rPPG.utils import masks as msk

def formatLossParts(lossParts, loss, suffix=''):
    formatted = {f'Loss{suffix}': loss}
    if len(lossParts) > 1:
        for name, lp in lossParts.items():
            formatted[f'Loss-{name}{suffix}'] = lp
    return formatted

def filterResults(results, columns=[]):
    if columns:
        return {col: res for col, res in results.items() if col in columns}
    return results

def test(model, config: dict, videos: str, gt: str = None, testSplit: str = 'test', testAll: bool = False, masks: str = None, save: str = None):
    """ Test a model
    
    Args:
      model: Pytorch model to use
      config: Config to use (must contain config['splits'])
      videos: Path to the videos on which to test
      gt: Path to the ground truth signals (optional if bundeled with videos)
      testSplit: Key in splits dictionary
      testAll: Ignore splits and test over all videos
      masks: Path to the masks (by default uses masks bundeled with videos if config.masks())
      save: Path to save evaluation results
    """
    from rPPG.utils.dataloader import Dataset
    from copy import deepcopy
    config = deepcopy(config)
    config['training']['augmentation'] = ''
    config['model']['fpc'] = config.val_test_fpc()
    if 'splits' not in config or testAll:
        config['splits'] = {testSplit: [Path(vid).stem for vid in Path(videos).iterdir()]}
    data = Dataset(config, config['splits'][testSplit], videos, gtDir=gt, maskDir=masks, ignoreMeta=True)
    print('Summary of test data:')
    tables.printTable(tables.mergeTables(data.getStats()))
    if save: # Save dataset stats
        Path(save).mkdir(exist_ok=True, parents=True)
        with (Path(save) / 'datasetStats.json').open('w') as f:
            json.dump(data.getStats(), f)
    if not data.HRs:
        print('ERROR: Must have ground truth signals for testing, but none found!')
        exit(1)
    predWaves, predHR, gtWaves, gtHR, loss, lossParts, predFFT = data.infer(model)
    # In memory constrained situations, evaluation can be an issue
    bySubject, valAvg = evaluate.evaluate(predWaves, predHR, gtWaves, gtHR, config.fps(), masks=data.masks, fft=predFFT, multiprocessing=config.multiprocessing())
    valAvg.update(formatLossParts(lossParts, loss))
    tables.printTable(filterResults(valAvg, config.columns()))
    if save:
        evaluate.saveAll(save, valAvg, bySubject, predWaves, predHR, gtWaves, gtHR, data.metadata, data.masks)
        save = Path(save)
        config['testresults'] = {'avg': valAvg, 'bySubject': bySubject}
        modelLoader.saveModelData(model.state_dict(), None, config, save / 'model')
        with (save / 'config.json').open('w') as f:
            json.dump(config, f)
    return bySubject, valAvg

if __name__ == '__main__':
    import argparse, argcomplete

    parser = argparse.ArgumentParser(description='Test an rPPG model over a dataset', formatter_class=argparse.ArgumentDefaultsHelpFormatter)
    parser.add_argument('model', help='Path to the model to test')
    parser.add_argument('gt', nargs='?', help='Path with ground truth waves where each filename is formatted subID.npz. By default uses gt bundled with the videos.')
    parser.add_argument('videos', help='Path to videos directory where each filename is formatted subID.npz')
    parser.add_argument('--config', help='Path to json-formatted configuration (see readme for details); by default uses config bundled with the network, falling back on entire video directory')
    parser.add_argument('--splits', help='Path to json-formatted splits file (see readme for details); by default uses splits saved to model config')
    parser.add_argument('--testSplit', help='Split over which to run the test (can be varied for debugging purposes)', default='test')
    parser.add_argument('--testAll', help='Skip splits and test over all data', action='store_true')
    parser.add_argument('--masks', help='Path to directory with masks as generated by utils/cleanLabels.py --outIntervals. By default uses masks bundled with the videos.')
    parser.add_argument('--nomasks', action='store_true', help='Explicitely omit using masks')
    parser.add_argument('--save', help='Path to save results')

    argcomplete.autocomplete(parser)
    args = parser.parse_args()

    # Load model
    model, config = modelLoader.load(args.model, args.config)

    if args.nomasks:
        if args.masks:
            raise ValueError('Cannot specify masks and nomasks simultaneously')
        if config.masks():
            config['training']['masks'] = False

    if args.splits:
        with open(args.splits) as f:
            config['splits'] = json.load(f)

    bySubject, valAvg = test(model, config, args.videos, args.gt, testSplit=args.testSplit, testAll=args.testAll, masks=args.masks, save=args.save)

