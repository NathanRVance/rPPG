#!/usr/bin/env python3
# PYTHON_ARGCOMPLETE_OK

import argparse, argcomplete

parser = argparse.ArgumentParser(description='Predict a pulse waveform for a cropped video', formatter_class=argparse.ArgumentDefaultsHelpFormatter)
parser.add_argument('video', help='npz formatted video')
parser.add_argument('output', help='Path to output npz waveform')
parser.add_argument('model', help='Weights for the model to use')
parser.add_argument('--config', help='Path to json-formatted configuration (see readme for details); by default uses config bundled with the network')
parser.add_argument('--mask', help='Path mask as generated by utils/cleanLabels.py --outIntervals')

argcomplete.autocomplete(parser)
args = parser.parse_args()

import numpy as np
from rPPG.utils.dataloader import Dataset
from rPPG.utils import modelLoader
from pathlib import Path
from rPPG.utils import npio

model, config = modelLoader.load(args.model, args.config)

print(f'Using device {next(model.parameters()).device}')

# We don't want to do any augmentations
config['training']['augmentation'] = ''
data = Dataset(config, [Path(args.video).stem], args.video, gtDir=None, maskDir=args.mask)

metadata = data.metadata[Path(args.video).stem]
if metadata:
    fps = metadata.fps()
    modelFPS = config.fps()
    if abs(modelFPS - fps) / fps > 0.25:
        print(f'ERROR: Using a model trained at {modelFPS} fps to infer over a video at {fps} fps')
        exit(1)

# Evaluate over the dataset
wave = list(data.infer(model, skipPostprocess=True)[0].values())[0]
npio.save(wave, metadata, args.output)
